{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e491130f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import shap\n",
    "from joblib import dump, load\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b758b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_datasets_info = torch.load('/Users/jiaming/Desktop/Lab2/datas/saved_datasets_scaled.pth')\n",
    "loaded_train_dataset = loaded_datasets_info['train_dataset']\n",
    "loaded_val_dataset = loaded_datasets_info['val_dataset']\n",
    "loaded_test_dataset = loaded_datasets_info['test_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1233275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def extract_features_labels_from_subset(subset):\n",
    "    \n",
    "    loader = DataLoader(subset, batch_size=len(subset))\n",
    "    \n",
    "    for features, labels in loader:\n",
    "        features = features.squeeze(1).numpy()\n",
    "        labels = labels.squeeze(1).numpy()\n",
    "        return features, labels\n",
    "\n",
    "X_train, y_train = extract_features_labels_from_subset(loaded_train_dataset)\n",
    "X_val, y_val = extract_features_labels_from_subset(loaded_val_dataset)\n",
    "X_test, y_test = extract_features_labels_from_subset(loaded_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cb35fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pd.read_csv('/Users/jiaming/Desktop/Lab2/datas/neg.csv') # 644\n",
    "feature_names = pos.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dde554b",
   "metadata": {},
   "source": [
    "# 4ML (LR + NB + RF + XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "917fda00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR -> LinearExplainer (need model, masker)\n",
    "# NB -> KernelExplainer (need model, shap.kmeans)\n",
    "# RF -> TreeExplainer (need model)\n",
    "# XGB -> Explainer (need model)\n",
    "\n",
    "# for constructing explainer, use train set\n",
    "# for get shap values with explainer, use test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e938fa88",
   "metadata": {},
   "source": [
    "## 1. LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "158ff24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = load('/Users/jiaming/Desktop/Lab2/datas/ROC/models/lr_model.joblib')\n",
    "\n",
    "masker = shap.maskers.Independent(data=X_train)\n",
    "explainer_lr = shap.LinearExplainer(lr_model, masker)  \n",
    "shap_values_lr = explainer_lr(X_test)\n",
    "\n",
    "shap_values_lr_reconstructed = shap.Explanation(values=shap_values_lr, \n",
    "                                             base_values=explainer_lr.expected_value, \n",
    "                                             data=X_test, \n",
    "                                             feature_names=feature_names)\n",
    "\n",
    "fig1_lr = shap.plots.bar(shap_values_lr_reconstructed, show=False) \n",
    "plt.savefig('/Users/jiaming/Desktop/Lab2/datas/SHAP/shap_fig1_lr.pdf', bbox_inches='tight')\n",
    "plt.close(fig1_lr) \n",
    "\n",
    "fig2_lr = shap.plots.beeswarm(shap_values_lr_reconstructed, show=False) \n",
    "plt.savefig('/Users/jiaming/Desktop/Lab2/datas/SHAP/shap_fig2_lr.pdf', bbox_inches='tight')\n",
    "plt.close(fig2_lr) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3aff07",
   "metadata": {},
   "source": [
    "## 2. NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5b9460dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cbe4db9cce4113b13918354610f46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# nb_model = load('/Users/jiaming/Desktop/Lab2/datas/ROC/models/nb_model.joblib') # has some issues\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "explainer_nb = shap.KernelExplainer(nb_model.predict_proba, shap.kmeans(X_train, 10))  \n",
    "shap_values_nb = explainer_nb(X_test)\n",
    "\n",
    "shap_values_nb_reconstructed = shap.Explanation(values=shap_values_nb.values[:,:,0], \n",
    "                                             base_values=explainer_nb.expected_value[0], \n",
    "                                             data=X_test, \n",
    "                                             feature_names=feature_names)\n",
    "\n",
    "fig1_nb = shap.plots.bar(shap_values_nb_reconstructed, show=False) \n",
    "plt.savefig('/Users/jiaming/Desktop/Lab2/datas/SHAP/shap_fig1_nb.pdf', bbox_inches='tight')\n",
    "plt.close(fig1_nb) \n",
    "\n",
    "fig2_nb = shap.plots.beeswarm(shap_values_nb_reconstructed, show=False) \n",
    "plt.savefig('/Users/jiaming/Desktop/Lab2/datas/SHAP/shap_fig2_nb.pdf', bbox_inches='tight')\n",
    "plt.close(fig2_nb) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae51056b",
   "metadata": {},
   "source": [
    "## 3. RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4e459572",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = load('/Users/jiaming/Desktop/Lab2/datas/ROC/models/rf_model.joblib')\n",
    "\n",
    "explainer_rf = shap.TreeExplainer(rf_model)\n",
    "shap_values_rf = explainer_rf(X_test)\n",
    "\n",
    "shap_values_rf_reconstructed = shap.Explanation(values=shap_values_rf.values[:,:,0], \n",
    "                                             base_values=explainer_rf.expected_value[0], \n",
    "                                             data=X_test, \n",
    "                                             feature_names=feature_names)\n",
    "\n",
    "fig1_rf = shap.plots.bar(shap_values_rf_reconstructed, show=False) \n",
    "plt.savefig('/Users/jiaming/Desktop/Lab2/datas/SHAP/shap_fig1_rf.pdf', bbox_inches='tight')\n",
    "plt.close(fig1_rf) \n",
    "\n",
    "fig2_rf = shap.plots.beeswarm(shap_values_rf_reconstructed, show=False) \n",
    "plt.savefig('/Users/jiaming/Desktop/Lab2/datas/SHAP/shap_fig2_rf.pdf', bbox_inches='tight')\n",
    "plt.close(fig2_rf) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde243f",
   "metadata": {},
   "source": [
    "## 4. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2f5abc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e30720927884aa1a9490a4b7050913b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n"
     ]
    }
   ],
   "source": [
    "svm_model = load('/Users/jiaming/Desktop/Lab2/datas/ROC/models/svm_model.joblib')\n",
    "\n",
    "explainer_svm = shap.KernelExplainer(svm_model.predict_proba, shap.kmeans(X_train, 10))  \n",
    "shap_values_svm = explainer_svm(X_test)\n",
    "\n",
    "shap_values_svm_reconstructed = shap.Explanation(values=shap_values_svm.values[:,:,0], \n",
    "                                             base_values=explainer_svm.expected_value[0], \n",
    "                                             data=X_test, \n",
    "                                             feature_names=feature_names)\n",
    "\n",
    "fig1_svm = shap.plots.bar(shap_values_svm_reconstructed, show=False) \n",
    "plt.savefig('/Users/jiaming/Desktop/Lab2/datas/SHAP/shap_fig1_svm.pdf', bbox_inches='tight')\n",
    "plt.close(fig1_svm) \n",
    "\n",
    "fig2_svm = shap.plots.beeswarm(shap_values_svm_reconstructed, show=False) \n",
    "plt.savefig('/Users/jiaming/Desktop/Lab2/datas/SHAP/shap_fig2_svm.pdf', bbox_inches='tight')\n",
    "plt.close(fig2_svm) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc11bc",
   "metadata": {},
   "source": [
    "# 2DL (LSTM + ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c37448c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_datasets_info = torch.load('/Users/jiaming/Desktop/Lab2/datas/saved_datasets_scaled.pth')\n",
    "loaded_train_dataset = loaded_datasets_info['train_dataset']\n",
    "loaded_val_dataset = loaded_datasets_info['val_dataset']\n",
    "loaded_test_dataset = loaded_datasets_info['test_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c83c76e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def extract_features_labels_from_subset(subset):\n",
    "    \n",
    "    loader = DataLoader(subset, batch_size=len(subset))\n",
    "    \n",
    "    for features, labels in loader:\n",
    "        features = features.squeeze(1).numpy()\n",
    "        labels = labels.squeeze(1).numpy()\n",
    "        return features, labels\n",
    "\n",
    "X_train, y_train = extract_features_labels_from_subset(loaded_train_dataset)\n",
    "X_val, y_val = extract_features_labels_from_subset(loaded_val_dataset)\n",
    "X_test, y_test = extract_features_labels_from_subset(loaded_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b5e8d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for deep learning model, here we expand 2nd dimension (channel) to 1 \n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1) \n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb1d716",
   "metadata": {},
   "source": [
    "## 1. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d709f0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BinaryLSTM(nn.Module):\n",
    "    def __init__(self, input_size=24, hidden_size=256, num_layers=2):\n",
    "        super(BinaryLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = self.linear(lstm_out[:, -1, :])\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "lstm_model = BinaryLSTM()\n",
    "lstm_model.load_state_dict(torch.load('/Users/jiaming/Desktop/Lab2/datas/ROC/models/LSTM/LSTM.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bcb6d28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n",
      "Warning: unrecognized nn.Module: LSTM\n"
     ]
    }
   ],
   "source": [
    "# warnings.filterwarnings(\"ignore\") # this code chunk will have warnings every time constructing the DeepExplainer\n",
    "\n",
    "explainer_lstm = shap.DeepExplainer(lstm_model, X_train_tensor) # X_train_tensor as background_data\n",
    "shap_values_lstm = explainer_lstm.shap_values(X_test_tensor) # 1. shap values\n",
    "\n",
    "lstm_model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = lstm_model(background_data)\n",
    "expected_value = predictions.numpy() # 2. base_values (which is just the expected value)\n",
    "\n",
    "shap_values_lstm_reconstructed = shap.Explanation(values=shap_values_lstm.squeeze(1), # construct back to only 2 dim\n",
    "                                             base_values=expected_value.squeeze(1), \n",
    "                                             data=X_test_tensor.squeeze(1), # construct back to only 2 dim\n",
    "                                             feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6135f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1_lstm = shap.plots.bar(shap_values_lstm_reconstructed, show=False)\n",
    "plt.savefig('/Users/jiaming/Desktop/Lab2/datas/SHAP/shap_fig1_lstm.pdf', bbox_inches='tight')\n",
    "plt.close(fig1_lstm)\n",
    "\n",
    "fig2_lstm = shap.plots.beeswarm(shap_values_lstm_reconstructed, show=False) \n",
    "plt.savefig('/Users/jiaming/Desktop/Lab2/datas/SHAP/shap_fig2_lstm.pdf', bbox_inches='tight')\n",
    "plt.close(fig2_lstm) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70731689",
   "metadata": {},
   "source": [
    "## 2. ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5d2d4f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 8\n",
    "class Net_conv(torch.nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(Net_conv, self).__init__()\n",
    "        self.block_1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=1,\n",
    "                            out_channels=size,\n",
    "                            kernel_size=1,\n",
    "                            stride=1,\n",
    "                            padding=0),\n",
    "            torch.nn.BatchNorm1d(size),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv1d(in_channels=size,\n",
    "                                out_channels=2*size,\n",
    "                                kernel_size=3,\n",
    "                                stride=1,\n",
    "                                padding=1),\n",
    "            torch.nn.BatchNorm1d(2*size)\n",
    "        )\n",
    "        self.block_2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=2*size,\n",
    "                            out_channels=4*size,\n",
    "                            kernel_size=1,\n",
    "                            stride=1,\n",
    "                            padding=0),\n",
    "            torch.nn.BatchNorm1d(4*size),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv1d(in_channels=4*size,\n",
    "                                out_channels=2*size,\n",
    "                                kernel_size=3, \n",
    "                                stride=1,\n",
    "                                padding=1),\n",
    "            torch.nn.BatchNorm1d(2*size)\n",
    "        )\n",
    "        iutput_size_block_1 = (input_length - 1 + 2 * 0) // 1 + 1  \n",
    "        output_size_block_2 = (iutput_size_block_1 - 1 + 2 * 0) // 1 + 1  \n",
    "        num_channels_last_layer = 2*size \n",
    "        linear_input_size = num_channels_last_layer * output_size_block_2    \n",
    "        self.linear_1 = torch.nn.Linear(linear_input_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        shortcut = x.float()\n",
    "        x = self.block_1(x)\n",
    "        x = torch.nn.functional.relu(x + shortcut)    \n",
    "        shortcut = x\n",
    "        x = self.block_2(x)\n",
    "        x = torch.nn.functional.relu(x + shortcut)     \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x =  self.linear_1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "resnet_model = Net_conv(input_length = 24)\n",
    "resnet_model.load_state_dict(torch.load('/Users/jiaming/Desktop/Lab2/datas/ROC/models/ResNet/ResNet.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "828b00e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings.filterwarnings(\"ignore\") # this code chunk will have warnings every time constructing the DeepExplainer\n",
    "\n",
    "explainer_resnet = shap.DeepExplainer(resnet_model, X_train_tensor) # X_train_tensor as background_data\n",
    "shap_values_resnet = explainer_resnet.shap_values(X_test_tensor) # 1. shap values\n",
    "\n",
    "resnet_model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = resnet_model(background_data)\n",
    "expected_value = predictions.numpy() # 2. base_values (which is just the expected value)\n",
    "\n",
    "shap_values_resnet_reconstructed = shap.Explanation(values=shap_values_resnet.squeeze(1), # construct back to only 2 dim\n",
    "                                             base_values=expected_value.squeeze(1), \n",
    "                                             data=X_test_tensor.squeeze(1), # construct back to only 2 dim\n",
    "                                             feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8e168412",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1_resnet = shap.plots.bar(shap_values_resnet_reconstructed, show=False)\n",
    "plt.savefig('/Users/jiaming/Desktop/Lab2/datas/SHAP/shap_fig1_resnet.pdf', bbox_inches='tight')\n",
    "plt.close(fig1_resnet)\n",
    "\n",
    "fig2_resnet = shap.plots.beeswarm(shap_values_resnet_reconstructed, show=False) \n",
    "plt.savefig('/Users/jiaming/Desktop/Lab2/datas/SHAP/shap_fig2_resnet.pdf', bbox_inches='tight')\n",
    "plt.close(fig2_resnet) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb8095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e5936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0047d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
